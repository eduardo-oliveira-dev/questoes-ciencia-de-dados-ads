{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1efe70b3",
   "metadata": {},
   "source": [
    "## **Classificação de Imagens de Raio-X com Redes Neurais Convolucionais (CNNs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b667f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /home/code-warden/anaconda3/lib/python3.13/site-packages (2.9.0+cpu)\n",
      "Requirement already satisfied: torchvision in /home/code-warden/anaconda3/lib/python3.13/site-packages (0.24.0+cpu)\n",
      "Requirement already satisfied: torchaudio in /home/code-warden/anaconda3/lib/python3.13/site-packages (2.9.0+cpu)\n",
      "Requirement already satisfied: filelock in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: torchmetrics in /home/code-warden/anaconda3/lib/python3.13/site-packages (1.8.2)\n",
      "Requirement already satisfied: numpy>1.20.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: packaging>17.1 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torchmetrics) (24.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torchmetrics) (2.9.0+cpu)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torchmetrics) (0.15.2)\n",
      "Requirement already satisfied: setuptools in /home/code-warden/anaconda3/lib/python3.13/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (72.1.0)\n",
      "Requirement already satisfied: typing_extensions in /home/code-warden/anaconda3/lib/python3.13/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->torchmetrics) (3.17.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->torchmetrics) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/code-warden/anaconda3/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b86b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas necessárias\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import zipfile\n",
    "\n",
    "# Definir sementes para reprodutibilidade\n",
    "torch.manual_seed(101010)\n",
    "np.random.seed(101010)\n",
    "random.seed(101010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b59f9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diretório de dados já existe.\n",
      "Diretório de validação data/chestxrays/val/NORMAL já contém arquivos. Pulando movimentação.\n",
      "Diretório de validação data/chestxrays/val/PNEUMONIA já contém arquivos. Pulando movimentação.\n"
     ]
    }
   ],
   "source": [
    "# --- Criação do Conjunto de Validação ---\n",
    "\n",
    "# Função para mover 50 arquivos aleatórios\n",
    "def mover_arquivos(dir_classe_origem, dir_classe_destino, n=50):\n",
    "    if not os.path.exists(dir_classe_destino):\n",
    "        os.makedirs(dir_classe_destino)\n",
    "    \n",
    "    # Verifica se já não foi movido\n",
    "    if len(os.listdir(dir_classe_destino)) > 0:\n",
    "        print(f\"Diretório de validação {dir_classe_destino} já contém arquivos. Pulando movimentação.\")\n",
    "        return\n",
    "\n",
    "    arquivos = os.listdir(dir_classe_origem)\n",
    "    # Garante que não tentará mover mais arquivos do que existem\n",
    "    qtd_para_mover = min(n, len(arquivos))\n",
    "    if qtd_para_mover < n:\n",
    "        print(f\"Aviso: Menos de {n} arquivos disponíveis em {dir_classe_origem}. Movendo {qtd_para_mover}.\")\n",
    "        \n",
    "    arquivos_aleatorios = random.sample(arquivos, qtd_para_mover)\n",
    "    for arquivo in arquivos_aleatorios:\n",
    "        shutil.move(os.path.join(dir_classe_origem, arquivo), os.path.join(dir_classe_destino, arquivo))\n",
    "\n",
    "# Descompactar os dados (se necessário)\n",
    "if not os.path.exists('data/chestxrays'):\n",
    "    print(\"Descompactando dados...\")\n",
    "    with zipfile.ZipFile('data/chestxrays.zip', 'r') as arquivo_zip:\n",
    "        arquivo_zip.extractall('data')\n",
    "else:\n",
    "    print(\"Diretório de dados já existe.\")\n",
    "\n",
    "# Mover 50 imagens de cada classe para a pasta de validação\n",
    "mover_arquivos('data/chestxrays/train/NORMAL', 'data/chestxrays/val/NORMAL')\n",
    "mover_arquivos('data/chestxrays/train/PNEUMONIA', 'data/chestxrays/val/PNEUMONIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2baa43fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: 200 imagens\n",
      "Dados de validação: 100 imagens\n",
      "Dados de teste: 100 imagens\n"
     ]
    }
   ],
   "source": [
    "# --- Definição das Transformações ---\n",
    "\n",
    "media_transformacao = [0.485, 0.456, 0.406]\n",
    "desvio_transformacao = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Transformação de TREINO com Data Augmentation\n",
    "transformacao_treino = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Garante que todas as imagens tenham o tamanho esperado pelo ResNet\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=media_transformacao, std=desvio_transformacao)\n",
    "])\n",
    "\n",
    "# Transformação de VALIDAÇÃO e TESTE (sem augmentation)\n",
    "transformacao_validacao_teste = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=media_transformacao, std=desvio_transformacao)\n",
    "])\n",
    "\n",
    "# --- Criação dos Datasets e DataLoaders ---\n",
    "\n",
    "# Aplicar as transformações\n",
    "dataset_treino = ImageFolder('data/chestxrays/train', transform=transformacao_treino)\n",
    "dataset_validacao = ImageFolder('data/chestxrays/val', transform=transformacao_validacao_teste)\n",
    "dataset_teste = ImageFolder('data/chestxrays/test', transform=transformacao_validacao_teste)\n",
    "\n",
    "# Definir tamanho do lote\n",
    "TAMANHO_LOTE = 32\n",
    "\n",
    "# Criar os data loaders\n",
    "carregador_treino = DataLoader(dataset_treino, batch_size=TAMANHO_LOTE, shuffle=True)\n",
    "carregador_validacao = DataLoader(dataset_validacao, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "carregador_teste = DataLoader(dataset_teste, batch_size=TAMANHO_LOTE, shuffle=False)\n",
    "\n",
    "print(f\"Dados de treino: {len(dataset_treino)} imagens\")\n",
    "print(f\"Dados de validação: {len(dataset_validacao)} imagens\")\n",
    "print(f\"Dados de teste: {len(dataset_teste)} imagens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9312a445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo ResNet-18 modificado e pronto.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------\n",
    "# Instanciar o modelo\n",
    "# --------------------------\n",
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "# --------------------------\n",
    "# Modificar o modelo\n",
    "# --------------------------\n",
    "# Congelar todos os parâmetros\n",
    "for parametro in resnet18.parameters():\n",
    "    parametro.requires_grad = False\n",
    "\n",
    "# Substituir a camada final (fully connected) para nossa classificação binária\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, 1)\n",
    "\n",
    "print(\"Modelo ResNet-18 modificado e pronto.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d20399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Função de treinamento 'treinar' definida.\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "# --------------------------------------------\n",
    "# Definir o loop de treinamento\n",
    "# --------------------------------------------\n",
    "\n",
    "def treinar(modelo, carregador_treino, carregador_validacao, funcao_perda, otimizador, num_epocas):\n",
    "    \n",
    "    # Inicializar métrica de acurácia\n",
    "    metrica_acuracia = Accuracy(task=\"binary\")\n",
    "    \n",
    "    for epoca in range(num_epocas):\n",
    "        # --- Fase de Treinamento ---\n",
    "        modelo.train()\n",
    "        perda_acumulada = 0.0\n",
    "        acuracia_acumulada = 0.0\n",
    "\n",
    "        for entradas, rotulos in carregador_treino:\n",
    "            otimizador.zero_grad()\n",
    "            \n",
    "            rotulos = rotulos.float().unsqueeze(1) # Ajustar formato para BCEWithLogitsLoss\n",
    "            saidas = modelo(entradas)\n",
    "            perda = funcao_perda(saidas, rotulos)\n",
    "            \n",
    "            perda.backward()\n",
    "            otimizador.step()\n",
    "\n",
    "            perda_acumulada += perda.item() * entradas.size(0)\n",
    "            # Calcular acurácia\n",
    "            predicoes = torch.sigmoid(saidas)\n",
    "            acuracia_acumulada += metrica_acuracia(predicoes, rotulos) * entradas.size(0)\n",
    "\n",
    "        perda_treino = perda_acumulada / len(dataset_treino)\n",
    "        acuracia_treino = acuracia_acumulada / len(dataset_treino)\n",
    "\n",
    "        # --- Fase de Validação ---\n",
    "        modelo.eval()\n",
    "        perda_validacao_acumulada = 0.0\n",
    "        acuracia_validacao_acumulada = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for entradas, rotulos in carregador_validacao:\n",
    "                rotulos = rotulos.float().unsqueeze(1)\n",
    "                saidas = modelo(entradas)\n",
    "                perda = funcao_perda(saidas, rotulos)\n",
    "                \n",
    "                perda_validacao_acumulada += perda.item() * entradas.size(0)\n",
    "                predicoes = torch.sigmoid(saidas)\n",
    "                acuracia_validacao_acumulada += metrica_acuracia(predicoes, rotulos) * entradas.size(0)\n",
    "\n",
    "        perda_validacao = perda_validacao_acumulada / len(dataset_validacao)\n",
    "        acuracia_validacao = acuracia_validacao_acumulada / len(dataset_validacao)\n",
    "\n",
    "        print(f'Época [{epoca+1}/{num_epocas}], '\n",
    "              f'Perda Treino: {perda_treino:.4f}, Acurácia Treino: {acuracia_treino:.4f}, '\n",
    "              f'Perda Val.: {perda_validacao:.4f}, Acurácia Val.: {acuracia_validacao:.4f}')\n",
    "\n",
    "print(\"Função de treinamento 'treinar' definida.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51cc2c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando o treinamento...\n",
      "Época [1/20], Perda Treino: 0.7609, Acurácia Treino: 0.4450, Perda Val.: 0.7208, Acurácia Val.: 0.4600\n",
      "Época [2/20], Perda Treino: 0.6619, Acurácia Treino: 0.6300, Perda Val.: 0.7904, Acurácia Val.: 0.5000\n",
      "Época [3/20], Perda Treino: 0.5880, Acurácia Treino: 0.7200, Perda Val.: 0.6614, Acurácia Val.: 0.6300\n",
      "Época [4/20], Perda Treino: 0.5586, Acurácia Treino: 0.7850, Perda Val.: 0.6475, Acurácia Val.: 0.6600\n",
      "Época [5/20], Perda Treino: 0.5124, Acurácia Treino: 0.7650, Perda Val.: 0.6967, Acurácia Val.: 0.5600\n",
      "Época [6/20], Perda Treino: 0.4868, Acurácia Treino: 0.8250, Perda Val.: 0.5606, Acurácia Val.: 0.8100\n",
      "Época [7/20], Perda Treino: 0.4447, Acurácia Treino: 0.8650, Perda Val.: 0.5187, Acurácia Val.: 0.8100\n",
      "Época [8/20], Perda Treino: 0.4177, Acurácia Treino: 0.8600, Perda Val.: 0.4840, Acurácia Val.: 0.7800\n",
      "Época [9/20], Perda Treino: 0.4066, Acurácia Treino: 0.8600, Perda Val.: 0.4443, Acurácia Val.: 0.8700\n",
      "Época [10/20], Perda Treino: 0.4055, Acurácia Treino: 0.8350, Perda Val.: 0.4312, Acurácia Val.: 0.8500\n",
      "Época [11/20], Perda Treino: 0.4005, Acurácia Treino: 0.8450, Perda Val.: 0.4048, Acurácia Val.: 0.8900\n",
      "Época [12/20], Perda Treino: 0.3860, Acurácia Treino: 0.8500, Perda Val.: 0.4063, Acurácia Val.: 0.8400\n",
      "Época [13/20], Perda Treino: 0.3418, Acurácia Treino: 0.8900, Perda Val.: 0.4079, Acurácia Val.: 0.8400\n",
      "Época [14/20], Perda Treino: 0.3584, Acurácia Treino: 0.8600, Perda Val.: 0.3984, Acurácia Val.: 0.8400\n",
      "Época [15/20], Perda Treino: 0.3510, Acurácia Treino: 0.8750, Perda Val.: 0.3960, Acurácia Val.: 0.8400\n",
      "Época [16/20], Perda Treino: 0.3752, Acurácia Treino: 0.8400, Perda Val.: 0.3637, Acurácia Val.: 0.8800\n",
      "Época [17/20], Perda Treino: 0.3057, Acurácia Treino: 0.8950, Perda Val.: 0.3758, Acurácia Val.: 0.8400\n",
      "Época [18/20], Perda Treino: 0.3420, Acurácia Treino: 0.8500, Perda Val.: 0.3896, Acurácia Val.: 0.8400\n",
      "Época [19/20], Perda Treino: 0.3421, Acurácia Treino: 0.8600, Perda Val.: 0.3546, Acurácia Val.: 0.8700\n",
      "Época [20/20], Perda Treino: 0.2897, Acurácia Treino: 0.9100, Perda Val.: 0.3858, Acurácia Val.: 0.8400\n",
      "Treinamento concluído.\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# Fine-tune o modelo (HIPERPARÂMETROS MODIFICADOS)\n",
    "# ----------------------------------------        \n",
    "        \n",
    "modelo = resnet18\n",
    "NUM_EPOCAS = 20 # Aumentado de 3 para 20\n",
    "TAXA_APRENDIZADO = 0.001 # Diminuído de 0.01 para 0.001\n",
    "\n",
    "# Otimizador treinará apenas os parâmetros da nova camada 'fc'\n",
    "otimizador = torch.optim.Adam(modelo.fc.parameters(), lr=TAXA_APRENDIZADO)\n",
    "\n",
    "# Função de perda para classificação binária\n",
    "funcao_perda = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "print(\"Iniciando o treinamento...\")\n",
    "treinar(modelo, carregador_treino, carregador_validacao, funcao_perda, otimizador, num_epocas=NUM_EPOCAS)\n",
    "print(\"Treinamento concluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6aac08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Avaliação Final no Conjunto de Teste ---\n",
      "Precisão (Precision): 0.8444\n",
      "\n",
      "Matriz de Confusão:\n",
      "(Linhas = Real, Colunas = Predito)\n",
      "         [0: Normal] [1: Pneumonia]\n",
      "[[43  7]\n",
      " [12 38]]\n"
     ]
    }
   ],
   "source": [
    "# Importar as métricas corretas da tarefa\n",
    "from torchmetrics import Precision, ConfusionMatrix\n",
    "\n",
    "# -----------------------\n",
    "# Código de Avaliação\n",
    "# ----------------------- \n",
    "\n",
    "modelo.eval()\n",
    "\n",
    "# Inicializar as métricas solicitadas\n",
    "metrica_precisao = Precision(task=\"binary\")\n",
    "metrica_matriz_confusao = ConfusionMatrix(task=\"binary\", num_classes=2)\n",
    "\n",
    "todas_predicoes = []\n",
    "todos_rotulos = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for entradas, rotulos in carregador_teste:\n",
    "    saidas = modelo(entradas)\n",
    "    \n",
    "    # Sigmoid + round para obter predições binárias (0 ou 1)\n",
    "    predicoes = torch.sigmoid(saidas).round() \n",
    "\n",
    "    todas_predicoes.extend(predicoes.cpu().tolist())\n",
    "    todos_rotulos.extend(rotulos.cpu().unsqueeze(1).tolist())\n",
    "\n",
    "# Converter listas para tensores DEPOIS que o loop terminar\n",
    "todas_predicoes = torch.tensor(todas_predicoes)\n",
    "todos_rotulos = torch.tensor(todos_rotulos)\n",
    "\n",
    "# Calcular métricas\n",
    "precisao_teste = metrica_precisao(todas_predicoes, todos_rotulos).item()\n",
    "matriz_confusao_teste = metrica_matriz_confusao(todas_predicoes, todos_rotulos)\n",
    " \n",
    "print(f\"\\n--- Avaliação Final no Conjunto de Teste ---\")\n",
    "print(f\"Precisão (Precision): {precisao_teste:.4f}\")\n",
    "print(f\"\\nMatriz de Confusão:\")\n",
    "print(f\"(Linhas = Real, Colunas = Predito)\")\n",
    "print(f\"         [0: Normal] [1: Pneumonia]\")\n",
    "print(matriz_confusao_teste.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d42ed",
   "metadata": {},
   "source": [
    "**Quais desafios foram encontrados no treinamento?**\n",
    "\n",
    "O modelo inicialmente não conseguia aprender, apresentando uma acurácia próxima de 50%. Isso foi causado pela falta de **aumento de dados (data augmentation)** e uma taxa de aprendizado muito alta (lr=0.01).\n",
    "\n",
    "No novo treinamento, a acurácia de treino (91%) terminou mais alta que a acurácia de validação (84%), o que indica um leve **overfitting**.\n",
    "\n",
    "A matriz de confusão mostrou 12 Falsos Negativos. Este é um desafio crítico, pois o modelo falhou em detectar a pneumonia em 12 casos. Reduzir esse número seria a prioridade."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be52a44",
   "metadata": {},
   "source": [
    "**Como melhorar o desempenho do modelo?**\n",
    "\n",
    "Atualmente, nós só treinamos a última camada (fc). A maior melhoria viria de \"descongelar\" algumas das camadas anteriores do ResNet e treiná-las com uma taxa de aprendizado muito pequena (ex: lr=0.00001). Isso permite que o modelo ajuste seus filtros pré-treinados especificamente para imagens de raio-X.\n",
    "\n",
    "Também poderíamos testar outras arquiteturas. O ResNet-18 é leve e rápido. Um modelo maior, como um ResNet-50 ou EfficientNet, poderia capturar padrões mais complexos e oferecer maior acurácia, ao custo de mais tempo de treinamento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
